{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dfossl/IWSS_ReactionPrediction_CoLab/blob/main/IWSS_ReactionPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hello!\n",
        "\n",
        "### This notebook was made as a more detailed walkthrough of code that was breifly mentioned in [my IWSS talk](https://video.unbc.ca/media/IWSS+January+21st+2022.mp4/0_jl9w5gyh/282400) on the appropriation of RNN language Seq2Seq models in reaction prediction. I made the notebook to explain some of the code/theory/math that was hand waved over in the talk.\n",
        "\n",
        "### The assume the notebook will be navigated by primarily undergraduate students who have some interest in Deep learning, so the notebook is constructed assuming that level education. I also will assume that the reader has the background provided in the talk.\n",
        "\n",
        "### Also feel it is important to note that [Schwaller et al. 2018](https://pubs.rsc.org/en/content/articlelanding/2018/sc/c8sc02339e) was the major inspiration for this work and the data is sourced form their paper.\n",
        "\n",
        "### Note: Still a work in progress. Will likely add more descriptions in future!\n",
        "\n",
        "### Have questions? --> Dylan.T.Fossl@gmail.com\n",
        "\n",
        "---\n",
        "\n",
        "If you stumbled on this but didn't watch the talk I would recommend it for important background.\n",
        "\n",
        "If you find any errors let me know!"
      ],
      "metadata": {
        "id": "fe2Mm90mYPf6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing libraries"
      ],
      "metadata": {
        "id": "8QUOr2NKZwL9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a8MdOm51Fodm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data\n",
        "Have and example dataset on my github. Samples 1100 reactions from an original dataest found [here](https://figshare.com/articles/Chemical_reactions_from_US_patents_1976-Sep2016_/5104873).\n",
        "\n",
        "Reactions are between 30 and 40 characters in length. Added the length constraint to make sure this subset was more uniform in size rather then sampling ransomly from the whole set."
      ],
      "metadata": {
        "id": "LZmJsV_aT_O3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_data = tf.keras.utils.get_file(fname=\"example_reaction_data_1100.csv\",\n",
        "                        origin=\"https://raw.githubusercontent.com/dfossl/IWSS_ReactionPrediction_CoLab/main/example_reaction_data_1100.csv\")"
      ],
      "metadata": {
        "id": "bjrdqQ0MTWt0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ec236d-85d5-46eb-f739-9210488220cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/dfossl/IWSS_ReactionPrediction_CoLab/main/example_reaction_data_1100.csv\n",
            "139264/131607 [===============================] - 0s 0us/step\n",
            "147456/131607 [=================================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can load the data with pandas and have a quick look."
      ],
      "metadata": {
        "id": "Q18wvsgfUkmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reactions = pd.read_csv(path_to_data, index_col=0, dtype=\"string\")\n",
        "reactions.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JyqQjCOsTqpK",
        "outputId": "ef38f284-aa22-4300-f8d9-c1a7bd763cf1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3182a506-0253-4f1c-a774-50efd6a9655f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reaction</th>\n",
              "      <th>Product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>895533</th>\n",
              "      <td>C c 1 n c 2 c c c c c 2 [nH] 1 . Cl C C C Br &gt;...</td>\n",
              "      <td>C c 1 n c 2 c c c c c 2 n 1 C C C Cl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29754</th>\n",
              "      <td>O = S ( Cl ) Cl . O C c 1 c c c c c 1 O c 1 c ...</td>\n",
              "      <td>Cl C c 1 c c c c c 1 O c 1 c c c c c 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377126</th>\n",
              "      <td>C O C ( = O ) c 1 c c ( C O ) c ( C ) o 1 &gt; A_...</td>\n",
              "      <td>C O C ( = O ) c 1 c c ( C = O ) c ( C ) o 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857844</th>\n",
              "      <td>N c 1 c c c c c 1 . O = C c 1 c c c o 1 &gt; A_Cl...</td>\n",
              "      <td>C ( = N / c 1 c c c c c 1 ) \\ c 1 c c c o 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2247</th>\n",
              "      <td>Cl c 1 n c n c c 1 O c 1 c c c c c 1 . [NH4+] ...</td>\n",
              "      <td>N c 1 n c n c c 1 O c 1 c c c c c 1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3182a506-0253-4f1c-a774-50efd6a9655f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3182a506-0253-4f1c-a774-50efd6a9655f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3182a506-0253-4f1c-a774-50efd6a9655f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 Reaction                                      Product\n",
              "895533  C c 1 n c 2 c c c c c 2 [nH] 1 . Cl C C C Br >...         C c 1 n c 2 c c c c c 2 n 1 C C C Cl\n",
              "29754   O = S ( Cl ) Cl . O C c 1 c c c c c 1 O c 1 c ...       Cl C c 1 c c c c c 1 O c 1 c c c c c 1\n",
              "377126  C O C ( = O ) c 1 c c ( C O ) c ( C ) o 1 > A_...  C O C ( = O ) c 1 c c ( C = O ) c ( C ) o 1\n",
              "857844  N c 1 c c c c c 1 . O = C c 1 c c c o 1 > A_Cl...  C ( = N / c 1 c c c c c 1 ) \\ c 1 c c c o 1\n",
              "2247    Cl c 1 n c n c c 1 O c 1 c c c c c 1 . [NH4+] ...          N c 1 n c n c c 1 O c 1 c c c c c 1"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reactions are SMILE strings that have already been tokenized. The tokens are seperated by spaces.\n",
        "\n",
        "If interested in the rules for tokenization they are described in [Schwaller et al. 2018](https://pubs.rsc.org/en/content/articlelanding/2018/sc/c8sc02339e).\n",
        "\n",
        "If interested in SMILES format see the [wiki](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system).\n",
        "\n",
        "---\n",
        "The reactions have the form:\n",
        "Reactants > Reagents > Products\n",
        "\n",
        ">  - **Reactants** are chemicals that are need for the reaction and go through a chemical change. Another way to say this is the reactants atoms can be mapped to the product.\n",
        "\n",
        ">  - **Reagents** are chemicals that are needed for the reaction but DO NOT go through a chemical change. In this dataste the reagents are unified into thier own single tokens. The idea there is that since the reagent does not map to the product the catorgization of its identity is enough to capture the importantance of its prescence. However, reagents can be general and may reagents can actually perform similar roles, so breaking reagents into normal tokens could allow the model to learn generality amoung reagents. Maybe an exercise for the readerimportantance of its prescence. However, reagents can be general and may reagents can actually perform similar roles, so breaking reagents into normal tokens could allow the model to learn generality amoung reagents. Maybe an exercise for the reader ðŸ˜‰.\n",
        "\n",
        "> - Products are a single SMILE. The dataset only contains reactions with single products.\n"
      ],
      "metadata": {
        "id": "G8dqmysWU0KA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(reactions, test_size=100)"
      ],
      "metadata": {
        "id": "651jKpPK7MiX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = test[test[\"Reaction\"].str.len() <= max(train[\"Reaction\"].str.len())]\n",
        "test = test[test[\"Product\"].str.len() <= max(train[\"Product\"].str.len())]"
      ],
      "metadata": {
        "id": "VSPJodxRa_T3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a TensorFlow Dataset\n",
        "\n",
        "Although not always necessary, we are utilizing [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) to create a tensorflow dataset. Tf datasets allow us to preset batch and buffer size."
      ],
      "metadata": {
        "id": "pWAH5h_g9Jrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(train)//4\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "trainDataset = tf.data.Dataset.from_tensor_slices((train[\"Reaction\"], train[\"Product\"])).shuffle(BUFFER_SIZE)\n",
        "trainDataset = trainDataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "icV8tsti9JIm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(train)//4\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "testDataset = tf.data.Dataset.from_tensor_slices((test[\"Reaction\"], test[\"Product\"])).shuffle(BUFFER_SIZE)\n",
        "testDataset = testDataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "5EgxI-_ZKeXk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can take a peak at what a batch looks like."
      ],
      "metadata": {
        "id": "96p97AU0qJ5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for example_rxn_batch, example_product_batch in trainDataset.take(-1):\n",
        "  print(f\"Batch input shape: {tf.shape(example_rxn_batch)}\")\n",
        "  print(f\"First 5 inputs of batch:\\n{example_rxn_batch[:5]}\")\n",
        "  print()\n",
        "  print(f\"Batch output shape: {tf.shape(example_rxn_batch)}\")\n",
        "  print(f\"First 5 outputs of batch:\\n{example_rxn_batch[:5]}\")\n",
        "  print()\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMuxpq1JKMER",
        "outputId": "e71e988e-3a8f-461a-b5bb-425852d9759e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch input shape: [32]\n",
            "First 5 inputs of batch:\n",
            "[b'N C C C N . O = C 1 O C ( = O ) c 2 n c c n c 2 1 > A_CCO'\n",
            " b'C = C C = C . C C ( = O ) O . O = O . O C C C C O >'\n",
            " b'C C ( C ) O c 1 c ( Cl ) c c c c 1 C O > A_c1ccccc1'\n",
            " b'C = C C O c 1 c c ( Br ) c ( F ) c c 1 Cl . O = C = O > A_C1CCOC1 A_Cl'\n",
            " b'c 1 c c c ( C 2 C N 3 C C S C 3 = N 2 ) c c 1 > A_O']\n",
            "\n",
            "Batch output shape: [32]\n",
            "First 5 outputs of batch:\n",
            "[b'N C C C N . O = C 1 O C ( = O ) c 2 n c c n c 2 1 > A_CCO'\n",
            " b'C = C C = C . C C ( = O ) O . O = O . O C C C C O >'\n",
            " b'C C ( C ) O c 1 c ( Cl ) c c c c 1 C O > A_c1ccccc1'\n",
            " b'C = C C O c 1 c c ( Br ) c ( F ) c c 1 Cl . O = C = O > A_C1CCOC1 A_Cl'\n",
            " b'c 1 c c c ( C 2 C N 3 C C S C 3 = N 2 ) c c 1 > A_O']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be processing the input text using the TextVectorization class provided by TensorFlow. It allows us write our own text processing function. In this case we will just be adding out START and END tokens."
      ],
      "metadata": {
        "id": "_49NJq6wq5_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_format_reactions(text):\n",
        "\n",
        "\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n"
      ],
      "metadata": {
        "id": "VDBnMo-38pZ7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the adapt() method can take some time. This is constructing our vocabulary for us."
      ],
      "metadata": {
        "id": "QnOyiY6GrQYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rxn_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_format_reactions)\n",
        "rxn_processor.adapt(train[\"Reaction\"])"
      ],
      "metadata": {
        "id": "s4rNO9hp88W0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "product_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_format_reactions)\n",
        "product_processor.adapt(train[\"Product\"])"
      ],
      "metadata": {
        "id": "vt4-FQuT-PL4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we call get_vocabulary() we can see a list of all of our tokens. "
      ],
      "metadata": {
        "id": "L2nRau0Nrpyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rxn_processor.get_vocabulary()[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psCM_rkRrb8j",
        "outputId": "807df0c3-0489-4aaa-c3a4-42ea3f5ea4b2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'c', 'C', '1']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our text processer can take in a string of tokens and provide use with and integer encoding. These integers are just the indices in the vocabulary.\n",
        "\n",
        "In this example we can see the zero paddings."
      ],
      "metadata": {
        "id": "Wrp2avX-xR7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Reaction: {example_rxn_batch[0]}')\n",
        "print(f\"Product: {rxn_processor(example_rxn_batch)[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V4SXfx_xkNq",
        "outputId": "d932572b-101f-41c4-a865-ca4eaea82599"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reaction: b'N C C C N . O = C 1 O C ( = O ) c 2 n c c n c 2 1 > A_CCO'\n",
            "Product: [ 9 13  3  3  3 13 12  5  8  3  4  5  3  7  8  5  6  2 14 15  2  2 15  2\n",
            " 14  4 11 32 10  0  0  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder\n",
        "\n",
        "With the data available we can explore the construction of the encoder.\n",
        "\n",
        "The encoder is just an RNN and we will be using [tf.keras.layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers) Module to construct the RNN.\n",
        "\n",
        "Give a few examples here."
      ],
      "metadata": {
        "id": "rdSKSE16JXg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a single layer RNN with 10 units\n",
        "cells = [tf.keras.layers.SimpleRNNCell(units=10)]\n",
        "example_encoder = tf.keras.layers.RNN(cells, return_sequences=True, return_state=True)"
      ],
      "metadata": {
        "id": "K7A5Y9ag0s6q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make example data\n",
        "print(f\"Shape before onehot (batch, seq_length): {tf.shape(rxn_processor(example_rxn_batch))}\")\n",
        "oneHot = tf.one_hot(rxn_processor(example_rxn_batch), rxn_processor.vocabulary_size())\n",
        "print(f\"Shape after onehot (batch, seq_length, vocab_size): {tf.shape(oneHot)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuGOqwhs1_3W",
        "outputId": "81fe858a-b403-46d3-e3df-00cf2dc03bd9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape before onehot (batch, seq_length): [32 32]\n",
            "Shape after onehot (batch, seq_length, vocab_size): [ 32  32 136]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we pass the data through the RNN we get two things returned. We get and output which holds the hidden states for each step of the RNN, this is important if we use attention. And we get the state, which for a simple RNN and the GRU is the '*h*' matrix shown in exmaples in the talk. For LSTM the state is a pair of matrices, *h* and *c* as discussed in the presentation.\n"
      ],
      "metadata": {
        "id": "EEFH7MoN3qzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pass through encoder\n",
        "output, state = example_encoder(oneHot)\n",
        "print(f\"Output shape (batch, seq_length, units): {tf.shape(output)}\")\n",
        "print(f\"Statet shape (batch, units): {tf.shape(state)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFlvGRIO3UzA",
        "outputId": "a7239233-12a3-4e43-ed4f-fbee0febfc40"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape (batch, seq_length, units): [32 32 10]\n",
            "Statet shape (batch, units): [32 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can do multiple layers like this:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ETxX7QslfANU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cells = [tf.keras.layers.SimpleRNNCell(units=10), tf.keras.layers.SimpleRNNCell(units=10)]\n",
        "example_encoder = tf.keras.layers.RNN(cells, return_sequences=True, return_state=True)\n"
      ],
      "metadata": {
        "id": "zQUWPGGqfDlD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the case of two layers we will have two states returned."
      ],
      "metadata": {
        "id": "gKeSQG0GgAiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "output, *state = example_encoder(oneHot)\n",
        "print(f\"Output shape (batch, seq_length, units): {tf.shape(output)}\")\n",
        "print(f\"Number of states: {len(state)}\")\n",
        "print(f\"State 1 shape (batch, units): {tf.shape(state[0])}\")\n",
        "print(f\"State 2 shape (batch, units): {tf.shape(state[1])}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLqiXgR1gA5z",
        "outputId": "7e7134f9-9c9e-4a20-b22d-06d09fce9782"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape (batch, seq_length, units): [32 32 10]\n",
            "Number of states: 2\n",
            "State 1 shape (batch, units): [32 10]\n",
            "State 2 shape (batch, units): [32 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we can do Bidirectionality like this:"
      ],
      "metadata": {
        "id": "RWbz82V_gbvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cells = [tf.keras.layers.SimpleRNNCell(units=10), tf.keras.layers.SimpleRNNCell(units=10)]\n",
        "example_encoder = tf.keras.layers.Bidirectional(tf.keras.layers.RNN(cells, return_sequences=True, return_state=True))\n",
        "output, *state = example_encoder(oneHot)\n",
        "print(f\"Output shape (batch, seq_length, units): {tf.shape(output)}\")\n",
        "print(f\"Number of states: {len(state)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-aXNoUVghSr",
        "outputId": "24f94aed-03bf-4201-b9b7-41877f989021"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape (batch, seq_length, units): [32 32 20]\n",
            "Number of states: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to point out here that the output has doubled in unit size. This is because my default the outputs are concatinated for the forward and backward RNNs. We also have 4 states for a bidirectional RNN with two layers. However, for bidirection it is important to combined the forward and reverse states. We can use [tf.keras.layers.Concatenate()](https://keras.io/api/layers/merging_layers/concatenate/) to do this. The returned states are going to follow the pattern of [layer_1_forward, layer_1_back, layer_2_forward, layer_2_back,...] repeated for each layer. \n",
        "\n",
        "So we can concatinate like this:"
      ],
      "metadata": {
        "id": "B3JDf1y_gwoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "states = [tf.keras.layers.Concatenate()([state[0], state[1]]), tf.keras.layers.Concatenate()([state[2], state[3]])]\n",
        "print(f\"Number of states: {len(states)}\")\n",
        "print(f\"State 1 shape (batch, units): {tf.shape(states[0])}\")\n",
        "print(f\"State 2 shape (batch, units): {tf.shape(states[1])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iycptVBEjOg4",
        "outputId": "799fa151-1e0f-42a0-f8a5-901bd0b25766"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of states: 2\n",
            "State 1 shape (batch, units): [32 20]\n",
            "State 2 shape (batch, units): [32 20]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I would reccomend playing around with the number of layers and bidirectional and cell types ([tf.keras.layers.GRUCell()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRUCell) or [tf.keras.layers.LSTMCell()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTMCell)).\n",
        "\n",
        "You'll notice that when you use LSTMs your state will return a context AND a hidden matrix. I'll leave it up to you to explore all of that but if you need hints you can look at future code where I handle this case."
      ],
      "metadata": {
        "id": "GyAEy9r7k85D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making Encoder Class\n",
        "\n",
        "In the Encoder we will be allowing for parameters for the layer type, number of layers and bidirectionality."
      ],
      "metadata": {
        "id": "Gje4VagXmJTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  \"\"\"\n",
        "  Custom Encoder class that extends Tensorflow layer.\n",
        "  Constructs an encoder of the provided architecture\n",
        "  \"\"\"\n",
        "  def __init__(self, input_vocab_size, enc_units, layer_type=\"rnn\", layers=1,\n",
        "                isBidirectional=False):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        input_vocab_size (int): size of input vocabulary.\n",
        "        enc_units (int): number of encoder units.\n",
        "        layer_type (str, optional): gru, rnn, or lstm. Defaults to \"rnn\".\n",
        "        layers (int, optional): Number of RNN layers. Defaults to 1.\n",
        "        isBidirectional (bool, optional): Use Bidirectionality. Defaults to False.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: For invalid layer type.\n",
        "    \"\"\"\n",
        "    super(Encoder, self).__init__()\n",
        "    self.enc_units = enc_units\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "    self.layer_type=layer_type\n",
        "    self.layers = layers\n",
        "    self.isBidirectional = isBidirectional\n",
        "\n",
        "\n",
        "\n",
        "    if not layer_type in {\"gru\", \"lstm\", \"rnn\"}:\n",
        "      raise ValueError(f\"[layer_type == {layer_type}]: layer_type must be one of:\\\n",
        "                          [gru, lstm, rnn]\")    \n",
        "\n",
        "    cells = []\n",
        "    if self.layer_type == \"gru\": \n",
        "      for _ in range(self.layers):\n",
        "        cells.append(tf.keras.layers.GRUCell(units=enc_units,\n",
        "                                              recurrent_initializer='glorot_uniform',\n",
        "                                              recurrent_dropout=.2))\n",
        "    elif self.layer_type == \"lstm\":\n",
        "      for _ in range(self.layers):\n",
        "        cells.append(tf.keras.layers.LSTMCell(units=enc_units,\n",
        "                                                recurrent_initializer='glorot_uniform',\n",
        "                                                recurrent_dropout=.2))\n",
        "    else:\n",
        "      for _ in range(self.layers):\n",
        "        cells.append(tf.keras.layers.SimpleRNNCell(units=enc_units,\n",
        "                                                    recurrent_initializer='glorot_uniform',\n",
        "                                                    recurrent_dropout=.2))\n",
        "\n",
        "    if self.isBidirectional:\n",
        "      self.rnn = tf.keras.layers.Bidirectional(tf.keras.layers.RNN(cells,\n",
        "                                                                  return_sequences=True,\n",
        "                                                                  return_state=True,\n",
        "                                                                  ))\n",
        "    else:\n",
        "      self.rnn = tf.keras.layers.RNN(cells,\n",
        "                                      return_sequences=True,\n",
        "                                      return_state=True,\n",
        "                                      )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5OccE0NoJS3t"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a helper function for getting the forward, backward state pairs for bidirectional networks."
      ],
      "metadata": {
        "id": "1t9qN7pPBQPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bidirectional_states(states, layer_num, layer_type, state=None):\n",
        "  \"\"\"Helper function that can retrieve the forward and reverse states for a given\n",
        "  layer in a bidrectional RNN. \n",
        "\n",
        "  Args:\n",
        "      states (List of Tensors): Holds returned output states from Bidirectional\n",
        "                                RNN model call.\n",
        "      layer_num (int): What layers state is being retrieved.\n",
        "      layer_type (str): gru, rnn, or lstm. lstm need special prcessing for context\n",
        "                        and hidden state.\n",
        "      state (str, optional): if lstm, then 'hidden' or 'context' must be provided\n",
        "                            to identify which state to return\n",
        "\n",
        "  Raises:\n",
        "      ValueError: If lstm is provided without a state.\n",
        "      ValueError: if rnn or gru are provided with a state.\n",
        "\n",
        "  Returns:\n",
        "      List of Tensors: Retrieves the forward and reverse states for given layer.\n",
        "  \"\"\"\n",
        "  start = 2*(layer_num-1)\n",
        "  if layer_type == \"lstm\":\n",
        "      if state == \"hidden\":\n",
        "          return [states[start][0], states[start+1][0]]\n",
        "      elif state == \"context\":\n",
        "          return [states[start][1], states[start+1][1]]\n",
        "      else:\n",
        "          raise ValueError(f\"[layer_type == lstm but state = {state}]: \\\n",
        "                            state must be 'hidden' or 'context' for lstm\")\n",
        "  elif layer_type in [\"rnn\", \"gru\"]:\n",
        "      if state:\n",
        "          raise ValueError(f\"[layer_type == {layer_type} but state = {state}]: \\\n",
        "                              state must be None for {layer_type}\")\n",
        "      \n",
        "      return [states[start], states[start+1]]"
      ],
      "metadata": {
        "id": "ITYlcu7gM-zp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call(self, tokens, state=None):\n",
        "  \n",
        "  oh_input = tf.one_hot(tokens, depth=self.input_vocab_size)\n",
        "\n",
        "  if self.isBidirectional:\n",
        "    if self.layer_type == \"lstm\":\n",
        "      # lstm need to concatinate both context and hidden states.\n",
        "      output, *s = self.rnn(oh_input, initial_state=state)\n",
        "      state = []\n",
        "      for i in range(self.layers):\n",
        "        layer_hidden_states = get_bidirectional_states(s, layer_num=i+1, \n",
        "                                                    layer_type=self.layer_type, \n",
        "                                                    state=\"hidden\")\n",
        "        concat_hidden_states = tf.keras.layers.Concatenate()(layer_hidden_states)\n",
        "\n",
        "        layer_context_states = get_bidirectional_states(s, layer_num=i+1, \n",
        "                                                    layer_type=self.layer_type, \n",
        "                                                    state=\"context\")\n",
        "        concat_context_states = tf.keras.layers.Concatenate()(layer_context_states)\n",
        "\n",
        "        state.append([concat_hidden_states, concat_context_states])\n",
        "    else:\n",
        "      # is GRU or RNN\n",
        "      output, *s = self.rnn(oh_input, initial_state=state)\n",
        "\n",
        "      state = []\n",
        "      for i in range(self.layers):\n",
        "        layerStates = get_bidirectional_states(s,\n",
        "                                              layer_num=i+1,\n",
        "                                              layer_type=self.layer_type)\n",
        "        state.append(tf.keras.layers.Concatenate()(layerStates))\n",
        "  else:\n",
        "    #Not Bidirectional\n",
        "    output, *state = self.rnn(oh_input, initial_state=state)\n",
        "\n",
        "  # In single layer networks state is either one tensor or a tuple of tensors\n",
        "  # in n layer networks state is a list of of n states for each layer n.\n",
        "  # Shapes:\n",
        "  # For GRU:  output (batch, max_input_len, dims)\n",
        "  #           state (1, dims)\n",
        "  # For LSTM: output (batch, max_input_len, dims)\n",
        "  #           state ( h(1, dims), c(1, dims) )\n",
        "  # For RNN:  output (batch, max_input_len, dims)\n",
        "  #           state (1, dims)\n",
        "  # If n layers then the number of states *n\n",
        "  # if bidirectional dims -> 2*dims because of concatination.\n",
        "  return output, state"
      ],
      "metadata": {
        "id": "r86a1Gp9NB-3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Encoder.call = call"
      ],
      "metadata": {
        "id": "RctshMklNDm3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can do some tests. Play around with different parameters!"
      ],
      "metadata": {
        "id": "BXucwBw3CbFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_tokens = rxn_processor(example_rxn_batch)\n",
        "encoder = Encoder(rxn_processor.vocabulary_size(), 128, layer_type=\"rnn\", layers=1, isBidirectional=False)\n",
        "example_enc_output, example_enc_state = encoder(example_tokens)\n",
        "\n",
        "print(f'Input batch, shape (batch): {example_rxn_batch.shape}')\n",
        "print(f'Input batch tokens, shape (batch, max_seq_length): {example_tokens.shape}')\n",
        "print(f'Encoder output, shape (batch, max_seq_length, units): {example_enc_output.shape}')\n",
        "for i in range(len(example_enc_state)):\n",
        "  print(f\"Encoder state {i+1} shape: {example_enc_state[i].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry4p2kQAJx9P",
        "outputId": "422c7e4c-4086-4158-f340-07539380fa01"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch, shape (batch): (32,)\n",
            "Input batch tokens, shape (batch, max_seq_length): (32, 32)\n",
            "Encoder output, shape (batch, max_seq_length, units): (32, 32, 128)\n",
            "Encoder state 1 shape: (32, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implimenting Attention\n",
        "\n",
        "Here we are going to use TensorFlows built in multiplicative attention mechanism (similar to Luong Attention). \n",
        "\n",
        "The query is the decoders hidden states, and query mask has which parts of the decoders output are padding. The value parameter is the encoders hidden states and the value mask provided is the mask for the encoders sequence to know which parts of encoder sequence were padding.\n",
        "\n",
        "By default the TesorFlow implimentation does not have weights, so we add a dense layer with no bias to act as the weighted matrix. \n"
      ],
      "metadata": {
        "id": "8ABv28tCDcmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class luong_like_attention(tf.keras.layers.Layer):\n",
        "  \"\"\"\n",
        "  Implimentation of Attention layer with tensorflows implimenation of\n",
        "  multiplicative attention.\n",
        "  \"\"\"\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "\n",
        "    self.attention = tf.keras.layers.Attention()\n",
        "\n",
        "  def call(self, query, query_mask, value, value_mask):\n",
        "\n",
        "    w1_query = self.W1(query)\n",
        "\n",
        "\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        inputs = [w1_query, value],\n",
        "        mask=[query_mask, value_mask],\n",
        "        return_attention_scores = True,\n",
        "    )\n",
        "\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "zJET6cVAMZ66"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we test out the attention layer we can see the output for the attention weights.\n",
        "\n",
        "We notice that the attention weights should have shape (batch_size, max_output_len, max_input_length). This is because for each output token there is a vector of size max_input_length that holds the weights for what input location to pay attention too."
      ],
      "metadata": {
        "id": "KDtOkF5zQC4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = luong_like_attention(128)\n",
        "\n",
        "example_attention_query = tf.random.normal(shape=[len(example_tokens), 32, 128])\n",
        "\n",
        "context_vector, attention_weights = attention_layer(\n",
        "    query=example_attention_query,\n",
        "    query_mask = (example_tokens != 0), # should be a unique mask just using as an example\n",
        "    value=example_enc_output,\n",
        "    value_mask=(example_tokens != 0))\n",
        "\n",
        "print(f'Attention layer output shape: (batch_size, max_output_len, units):           {context_vector.shape}')\n",
        "print(f'Attention weights shape: (batch_size, max_output_len, max_input_length): {attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCFYbn8nLLCD",
        "outputId": "b90ad06b-18c4-4220-c254-03dcd4626773"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention layer output shape: (batch_size, max_output_len, units):           (32, 32, 128)\n",
            "Attention weights shape: (batch_size, max_output_len, max_input_length): (32, 32, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EzVzCkjgQ-Ex"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implimenting Decoder\n",
        "\n",
        "This will have a very similar structure to the Encoder in that it is just an RNN. It will have an additional Dense layer for the output since we need the decoder to output vectors with size equal to the max output sequence to actually get the one hot encoding for the predictived character. The Decoder will also have a attention layer.\n",
        "\n",
        "Note decoder is not given bidirection option since decoder needs to produce a a sequence and cannot see ahead of where it is at."
      ],
      "metadata": {
        "id": "w3F8KEC9RzhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  \"\"\"\n",
        "  Custom decoder class that impliments tensor flow layer.\n",
        "  \"\"\"\n",
        "  def __init__(self, output_vocab_size, dec_units, layer_type=\"rnn\", layers=1, useAttention=True):\n",
        "    \"\"\"\n",
        "    Given vocab size, units, layer_type, number of layers, and attention and constructs a decoder\n",
        "    of those properties.\n",
        "    \"\"\"\n",
        "    super(Decoder, self).__init__()\n",
        "    self.dec_units = dec_units\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "\n",
        "    self.layer_type=layer_type\n",
        "    self.layers = layers\n",
        "    self.useAttention = useAttention\n",
        "\n",
        "    if not layer_type in {\"gru\", \"lstm\", \"rnn\"}:\n",
        "      raise ValueError(f\"[layer_type == {layer_type}]: layer_type must be one of: [gru, lstm, rnn]\")    \n",
        "\n",
        "    cells = []\n",
        "    if self.layer_type == \"gru\": \n",
        "      for _ in range(self.layers):\n",
        "        cells.append(tf.keras.layers.GRUCell(units=dec_units,\n",
        "                                             recurrent_initializer='glorot_uniform',\n",
        "                                             dropout=.3))\n",
        "    elif self.layer_type == \"lstm\":\n",
        "      for _ in range(self.layers):\n",
        "\n",
        "        cells.append(tf.keras.layers.LSTMCell(units=dec_units,\n",
        "                                             recurrent_initializer='glorot_uniform',\n",
        "                                             dropout=.3))\n",
        "    else:\n",
        "      # rnn\n",
        "      for _ in range(self.layers):\n",
        "        cells.append(tf.keras.layers.SimpleRNNCell(units=dec_units,\n",
        "                                             recurrent_initializer='glorot_uniform',\n",
        "                                             dropout=.3))\n",
        "\n",
        "    self.rnn = tf.keras.layers.RNN(cells, return_sequences=True, return_state=True)\n",
        "    \n",
        "    if self.useAttention:\n",
        "      self.attention = luong_like_attention(self.dec_units)\n",
        "\n",
        "      # This weighted matrix is for applying the context vector to decoder\n",
        "      # output\n",
        "      self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
        "                                      use_bias=False)\n",
        "\n",
        "    self.fc = tf.keras.layers.Dense(self.output_vocab_size)\n",
        "\n",
        "  def call(self, inputs, state=None):\n",
        "\n",
        "      vectors = tf.one_hot(inputs[\"input_tokens\"], depth=self.output_vocab_size)\n",
        "\n",
        "\n",
        "      rnn_output, *state = self.rnn(vectors, initial_state=state)\n",
        "\n",
        "\n",
        "      if self.useAttention:\n",
        "        context_vector, attention_weights = self.attention(\n",
        "            query=rnn_output, query_mask = inputs[\"dec_mask\"], value=inputs[\"enc_output\"], value_mask=inputs[\"enc_mask\"])\n",
        "\n",
        "        context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
        "\n",
        "        last_vector = self.Wc(context_and_rnn_output)\n",
        "\n",
        "        \n",
        "      else:\n",
        "        attention_weights = None\n",
        "        last_vector = rnn_output\n",
        "\n",
        "      \n",
        "      logits = self.fc(last_vector)\n",
        "\n",
        "      return {\"logits\":logits, \"attention_weights\":attention_weights}, state"
      ],
      "metadata": {
        "id": "Ai-_VWI_SPBT"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set up example Encoder\n",
        "example_tokens = rxn_processor(example_rxn_batch)\n",
        "encoder = Encoder(rxn_processor.vocabulary_size(), 128, layer_type=\"rnn\", layers=1, isBidirectional=False)\n",
        "example_enc_output, example_enc_state = encoder(example_tokens)\n",
        "\n",
        "#Set up example Decoder\n",
        "decoder = Decoder(product_processor.vocabulary_size(), 128, layer_type=\"rnn\", useAttention=True)\n",
        "example_output_tokens = product_processor(example_product_batch)\n",
        "decoder_input = {\"input_tokens\":example_output_tokens[:,:-1],\n",
        "                 \"dec_mask\":example_output_tokens[:,:-1] != 0,\n",
        "                 \"enc_output\":example_enc_output,\n",
        "                 \"enc_mask\":example_tokens!=0}\n",
        "\n",
        "dec_result, dec_state = decoder(decoder_input, example_enc_state)\n",
        "\n",
        "print(f\"input tokens shape (batch, max_seq_len-1): {decoder_input['input_tokens'].shape}\")\n",
        "print(f'logits shape: (batch_size, product_max_len-1, product_vocab_size) {dec_result[\"logits\"].shape}')\n",
        "for i in range(len(dec_state)):\n",
        "  print(f'state {i+1} shape: (batch_size, dec_units) {dec_state[i].shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgmExaubSmgE",
        "outputId": "b44eaf8c-5ee6-4e35-d930-c8383feef9fe"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input tokens shape (batch, max_seq_len-1): (32, 28)\n",
            "logits shape: (batch_size, product_max_len-1, product_vocab_size) (32, 28, 41)\n",
            "state 1 shape: (batch_size, dec_units) (32, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some additional functions.\n"
      ],
      "metadata": {
        "id": "HBeEGvqybGok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MaskedLoss extends Loss and makes sure the categorical cross entropy is only calculated for unmasked values."
      ],
      "metadata": {
        "id": "7fbF_j4wvYU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedLoss(tf.keras.losses.Loss):\n",
        "  \"\"\"\n",
        "  Extenstion of Tensorflow lost class for masking padding values.\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    self.name = 'masked_loss'\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction=\"sum\")\n",
        "\n",
        "  def __call__(self, y_true, y_pred):\n",
        "\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = y_true != 0\n",
        "    mask = tf.cast(mask, dtype=tf.int64)\n",
        "\n",
        "    loss = self.loss(y_true, y_pred, sample_weight=mask)\n",
        "\n",
        "\n",
        "\n",
        "    # We divide loss by reduce sum of mask as this allows us\n",
        "    # to divide by the number of unmasked values.\n",
        "    return loss / tf.reduce_sum(tf.cast(mask, tf.float32))\n"
      ],
      "metadata": {
        "id": "TarVoRwtbNVi"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MaskedTotalAccuracy extends metric and gives the total accuracy rather then sequence accracy."
      ],
      "metadata": {
        "id": "IQ-Thz2TvmBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedTotalAccuracy(tf.keras.metrics.Metric):\n",
        "\n",
        "  def __init__(self, name=\"masked_tot_acc\", **kwargs):\n",
        "    super(MaskedTotalAccuracy, self).__init__(name=name, **kwargs)\n",
        "    self.sum_batch_acc = self.add_weight(name=\"Sum of Average Prediction Accuracies\", initializer=\"zeros\")\n",
        "    self.num_batches = self.add_weight(name=\"Number of Batches called\", initializer=\"zeros\")\n",
        "    \n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "\n",
        "    # holds 1 for correct guess and 0 for wrong guess\n",
        "    equality_true_and_pred = tf.math.equal(tf.cast(y_true, dtype=tf.int32), \n",
        "                                              tf.cast(tf.math.argmax(y_pred, axis=-1), dtype=tf.int32))\n",
        "\n",
        "\n",
        "    if sample_weight is not None:\n",
        "\n",
        "      # Negate mask to make all masked values 1\n",
        "      n_sample_weight = tf.logical_not(tf.cast(sample_weight, dtype=tf.bool))\n",
        "\n",
        "      # Since all masked values are 1 the logical or forces all padding guesses to be true\n",
        "      # For total acuracy this is fine because the percentage right isn't being messaged\n",
        "      # only the totality of correctness. In this way guesses can only be wrong in\n",
        "      # non-padding regions.\n",
        "      masked_results = tf.logical_or(n_sample_weight, equality_true_and_pred)\n",
        "    else:\n",
        "      masked_results = equality_true_and_pred\n",
        "\n",
        "\n",
        "    collapsed_results = tf.reduce_all(masked_results, axis=1, keepdims=True)\n",
        "\n",
        "\n",
        "    batch_number_true_positives = tf.reduce_sum(tf.cast(collapsed_results, dtype=tf.float32))\n",
        "\n",
        "    batch_acc = batch_number_true_positives / tf.cast(tf.shape(y_true)[0], dtype=tf.float32)\n",
        "    self.sum_batch_acc.assign_add(batch_acc)\n",
        "\n",
        "    self.num_batches.assign_add(1.)\n",
        "\n",
        "\n",
        "  def result(self):\n",
        "    # Return the current average batch accruacy\n",
        "    return self.sum_batch_acc/self.num_batches\n",
        "  \n",
        "  def reset_state(self):\n",
        "    self.sum_batch_acc.assign(0.)\n",
        "    self.num_batches.assign(0.)\n"
      ],
      "metadata": {
        "id": "7VGyoZcoqdAT"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General Model Constructor"
      ],
      "metadata": {
        "id": "JTj0zXpx1wKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqModelConstructor(tf.keras.Model):\n",
        "  \"\"\"\n",
        "  Seq2SeqModelConstructor extends Tensorflow model and handles the creation of the full model with\n",
        "  encoder and decoder and impliments the custom training and evaluation steps.\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "               units,\n",
        "               input_rxn_processor,\n",
        "               output_rxn_processor,\n",
        "               output_vocab_size,\n",
        "               n_layers=1,\n",
        "               layer_type=\"rnn\",\n",
        "               isBidirectional=False,\n",
        "               useAttention=True):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    self.input_rxn_processor = input_rxn_processor\n",
        "    self.output_rxn_processor = output_rxn_processor\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "    self.n_layers = n_layers\n",
        "    self.layer_type = layer_type\n",
        "    self.isBidirectional = isBidirectional\n",
        "    self.useAttention = useAttention\n",
        "\n",
        "\n",
        "    self.encoder = Encoder(input_vocab_size=input_rxn_processor.vocabulary_size(),\n",
        "                        enc_units=units,\n",
        "                        layer_type=self.layer_type,\n",
        "                        layers=self.n_layers,\n",
        "                        isBidirectional=self.isBidirectional)\n",
        "    \n",
        "\n",
        "    if self.isBidirectional:\n",
        "      dec_units = 2*units\n",
        "    else:\n",
        "      dec_units = units\n",
        "    \n",
        "\n",
        "    self.decoder = Decoder(output_vocab_size=output_rxn_processor.vocabulary_size(),\n",
        "                                  dec_units=dec_units,\n",
        "                                  layer_type=self.layer_type,\n",
        "                                  layers=self.n_layers,\n",
        "                                  useAttention=self.useAttention)\n",
        "    \n",
        "\n",
        "    self.seq_acc_1 = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=1)\n",
        "    self.seq_acc_2 = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=2)\n",
        "    self.seq_acc_3 = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3)\n",
        "    self.seq_acc_4 = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=4)\n",
        "    self.seq_acc_5 = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5)\n",
        "    self.tot_acc = MaskedTotalAccuracy()\n",
        "\n",
        "  \n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return [self.seq_acc_1,self.seq_acc_2,self.seq_acc_3,self.seq_acc_4,self.seq_acc_5,self.tot_acc]"
      ],
      "metadata": {
        "id": "-2W3j0eg-mS_"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper methods for Seq2Seq model"
      ],
      "metadata": {
        "id": "ebrmOAL09PlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k_acc_loop(self, y_true, y_pred):\n",
        "  \"\"\"\n",
        "  This only is needed because the Keras topKaccruacy seems to have issues with\n",
        "  Batches?\n",
        "  Here is my open issue:\n",
        "  https://github.com/keras-team/keras/issues/15939\n",
        "  \"\"\"\n",
        "  mask = tf.math.logical_not(tf.math.equal(y_true, 0))\n",
        "  \n",
        "  mask = tf.cast(mask, dtype=tf.int32)\n",
        "\n",
        "  for i in tf.range(tf.shape(y_true)[0]):\n",
        "    self.seq_acc_1.update_state(y_true[i,:], y_pred[i,:,:], sample_weight=mask[i,:])\n",
        "    self.seq_acc_2.update_state(y_true[i,:], y_pred[i,:,:], sample_weight=mask[i,:])\n",
        "    self.seq_acc_3.update_state(y_true[i,:], y_pred[i,:,:], sample_weight=mask[i,:])\n",
        "    self.seq_acc_4.update_state(y_true[i,:], y_pred[i,:,:], sample_weight=mask[i,:])\n",
        "    self.seq_acc_5.update_state(y_true[i,:], y_pred[i,:,:], sample_weight=mask[i,:])\n",
        "\n",
        "Seq2SeqModelConstructor.top_k_acc_loop = top_k_acc_loop"
      ],
      "metadata": {
        "id": "5sVmRY4o9Liq"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(self, input_text, target_text):\n",
        "  # Convert the text to token IDs\n",
        "  input_tokens = self.input_rxn_processor(input_text)\n",
        "  target_tokens = self.output_rxn_processor(target_text)\n",
        "\n",
        "\n",
        "  # Convert IDs to masks.\n",
        "  input_mask = input_tokens != 0\n",
        "\n",
        "\n",
        "  target_mask = target_tokens != 0\n",
        "\n",
        "\n",
        "  return input_tokens, input_mask, target_tokens, target_mask\n",
        "\n",
        "Seq2SeqModelConstructor._preprocess = preprocess"
      ],
      "metadata": {
        "id": "Rjq6oty9_d9A"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NKiMJEiZCide"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is one thing I neglatcted to mention in the talk to save time but is an important detail for this training process. In traing we are using something called [teacher forcing](https://en.wikipedia.org/wiki/Teacher_forcing). The main idea is in training rather then feeding outputs of the decoder back into itself we actually feed the correct token in each time regardless of the prediciton. Intuitivly what this is doing is making sure that even if the decoder is making mistakes early on that these mistakes don't compound over the sequence.\n",
        "\n",
        "An anology is if we treat training like a test. Sequence prediction is one of those questions that has part 'c' depend on part 'b' and part 'b' depend on part 'a'. Teacher forcing is like a nice techaer that will give you 'a' even if you got it wrong so you atleast have a shot at doing 'b'.\n",
        "\n",
        "---\n",
        "\n",
        "We impliment train_step so that we can call model.fit()\n",
        "If you want you can always make you're own custom training loop!"
      ],
      "metadata": {
        "id": "mL5zopqdSb-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
        "                              tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
        "def train_step(self, inputs):\n",
        "  input_text, target_text = inputs\n",
        "\n",
        "\n",
        "  (input_tokens, input_mask,\n",
        "  target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
        "\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "    dec_state = enc_state\n",
        "\n",
        "\n",
        "    decoder_input = {\"input_tokens\":target_tokens[:, :-1],\n",
        "                                \"dec_mask\":target_mask[:, :-1],\n",
        "                                \"enc_output\":enc_output,\n",
        "                                \"enc_mask\":input_mask}\n",
        "\n",
        "    dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
        "\n",
        "\n",
        "    y = target_tokens[:,1:]\n",
        "    y_pred = dec_result[\"logits\"]\n",
        "    average_loss = self.loss(y, y_pred)\n",
        "    self.tot_acc.update_state(y, y_pred, target_mask[:,1:])\n",
        "\n",
        "\n",
        "    self.top_k_acc_loop(y, y_pred)\n",
        "\n",
        "\n",
        "    acc_top1 = self.seq_acc_1.result()\n",
        "    acc_top2 = self.seq_acc_2.result()\n",
        "    acc_top3 = self.seq_acc_3.result()\n",
        "    acc_top4 = self.seq_acc_4.result()\n",
        "    acc_top5 = self.seq_acc_5.result()\n",
        "    totA = self.tot_acc.result()\n",
        "\n",
        "    \n",
        "      \n",
        "  variables = self.trainable_variables \n",
        "  gradients = tape.gradient(average_loss, variables)\n",
        "  self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "\n",
        "  return {'batch_loss': average_loss,\n",
        "          \"acc_1\":acc_top1,\n",
        "          \"acc_2\":acc_top2,\n",
        "          \"acc_3\":acc_top3,\n",
        "          \"acc_4\":acc_top4,\n",
        "          \"acc_5\":acc_top5,\n",
        "          \"totA\":totA}\n",
        "\n",
        "Seq2SeqModelConstructor.train_step = train_step"
      ],
      "metadata": {
        "id": "t68_ZBew-SKo"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test_step is necessary for being able to call model.evaluate(). In this case test_step still uses the teacher forcing workflow. For true evaluation this is bad but for the propose of seeing how the test and training results compare in the best contexts. We will impliment our own evaluate for real evaluation."
      ],
      "metadata": {
        "id": "jUz2nzh6RnbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
        "                              tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
        "def test_step(self, inputs):\n",
        "  input_text, target_text = inputs\n",
        "\n",
        "\n",
        "  (input_tokens, input_mask,\n",
        "  target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
        "\n",
        "  enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "  dec_state = enc_state\n",
        "\n",
        "\n",
        "  decoder_input = {\"input_tokens\":target_tokens[:, :-1],\n",
        "                              \"dec_mask\":target_mask[:, :-1],\n",
        "                              \"enc_output\":enc_output,\n",
        "                              \"enc_mask\":input_mask}\n",
        "\n",
        "  dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
        "\n",
        "\n",
        "  y = target_tokens[:,1:]\n",
        "  y_pred = dec_result[\"logits\"]\n",
        "\n",
        "\n",
        "  average_loss = self.loss(y, y_pred)\n",
        "  self.tot_acc.update_state(y, y_pred, target_mask[:,1:])\n",
        "\n",
        "\n",
        "  self.top_k_acc_loop(y, y_pred)\n",
        "\n",
        "\n",
        "  acc_top1 = self.seq_acc_1.result()\n",
        "  acc_top2 = self.seq_acc_2.result()\n",
        "  acc_top3 = self.seq_acc_3.result()\n",
        "  acc_top4 = self.seq_acc_4.result()\n",
        "  acc_top5 = self.seq_acc_5.result()\n",
        "  totA = self.tot_acc.result()\n",
        "\n",
        "  return {'batch_loss': average_loss,\n",
        "          \"acc_1\":acc_top1,\n",
        "          \"acc_2\":acc_top2,\n",
        "          \"acc_3\":acc_top3,\n",
        "          \"acc_4\":acc_top4,\n",
        "          \"acc_5\":acc_top5,\n",
        "          \"totA\":totA}\n",
        "\n",
        "Seq2SeqModelConstructor.test_step = test_step"
      ],
      "metadata": {
        "id": "iNx3rnaQyFOZ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This evaluation function will feed decoder outputs back in as inputs to get real prediction evaluation."
      ],
      "metadata": {
        "id": "jN27JYj2R6iQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_dataset(self, dataset):\n",
        "  \"\"\"\n",
        "  Loops over dataset batches calculating and printing metrics\n",
        "  for each batch. Final results are the batch averages.\n",
        "\n",
        "  @return Dictionary with Batch average of metrics.\n",
        "  \"\"\"\n",
        "\n",
        "  total_loss = 0\n",
        "  acc_top1 = 0\n",
        "  acc_top2 = 0\n",
        "  acc_top3 = 0\n",
        "  acc_top4 = 0\n",
        "  acc_top5 = 0\n",
        "  totA = 0\n",
        "\n",
        "  for batch, (input_text, target_text) in enumerate(dataset.take(-1)):\n",
        "\n",
        "\n",
        "    (input_tokens, input_mask,\n",
        "    target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
        "\n",
        "\n",
        "\n",
        "    max_target_length = tf.shape(target_tokens)[1]\n",
        "\n",
        "\n",
        "    enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "    dec_state = enc_state\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    pred_tokens = target_tokens[:, 0:1]\n",
        "    \n",
        "    for t in range(max_target_length-1):\n",
        "\n",
        "\n",
        "      decoder_input = {\"input_tokens\":pred_tokens,\n",
        "                            \"dec_mask\":target_mask[:, t:t+1],\n",
        "                            \"enc_output\":enc_output,\n",
        "                            \"enc_mask\":input_mask}\n",
        "\n",
        "\n",
        "      dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
        "\n",
        "      if t == 0:\n",
        "        logits = dec_result[\"logits\"]\n",
        "      else:\n",
        "        logits = tf.concat((logits, dec_result[\"logits\"]), 1)\n",
        "\n",
        "      pred_tokens = tf.argmax(dec_result[\"logits\"], -1)\n",
        "    \n",
        "\n",
        "    y = target_tokens[:,1:]\n",
        "    y_pred = logits\n",
        "\n",
        "    loss = self.loss(y, y_pred).numpy()\n",
        "\n",
        "    total_loss += loss\n",
        "\n",
        "    self.tot_acc.update_state(y, y_pred, target_mask[:,1:])\n",
        "\n",
        "\n",
        "    self.top_k_acc_loop(y, y_pred)\n",
        "\n",
        "    print((f\"Batch: {batch} - batch_loss: {loss:.3f} -\"),\n",
        "          (f\"acc_1: {self.seq_acc_1.result().numpy():.3f} -\"),\n",
        "          (f\"acc_2: {self.seq_acc_2.result().numpy():.3f} -\"),\n",
        "          (f\"acc_3: {self.seq_acc_3.result().numpy():.3f} -\"),\n",
        "          (f\"acc_4: {self.seq_acc_4.result().numpy():.3f} -\"),\n",
        "          (f\"acc_5: {self.seq_acc_5.result().numpy():.3f} -\"),\n",
        "          (f\"TotA: {self.tot_acc.result().numpy():.3f}\"))\n",
        "    \n",
        "    acc_top1 += self.seq_acc_1.result().numpy()\n",
        "    acc_top2 += self.seq_acc_2.result().numpy()\n",
        "    acc_top3 += self.seq_acc_3.result().numpy()\n",
        "    acc_top4 += self.seq_acc_4.result().numpy()\n",
        "    acc_top5 += self.seq_acc_5.result().numpy()\n",
        "    totA += self.tot_acc.result().numpy()\n",
        "\n",
        "    self.seq_acc_1.reset_state()\n",
        "    self.seq_acc_2.reset_state()\n",
        "    self.seq_acc_3.reset_state()\n",
        "    self.seq_acc_4.reset_state()\n",
        "    self.seq_acc_5.reset_state()\n",
        "    self.tot_acc.reset_state()\n",
        "\n",
        "\n",
        "  return {\"batch_loss\":total_loss/(batch+1),\n",
        "          \"acc_1\":acc_top1/(batch+1),\n",
        "          \"acc_2\":acc_top2/(batch+1),\n",
        "          \"acc_3\":acc_top3/(batch+1),\n",
        "          \"acc_4\":acc_top4/(batch+1),\n",
        "          \"acc_5\":acc_top5/(batch+1),\n",
        "          \"totA\":totA/(batch+1)}\n",
        "\n",
        "Seq2SeqModelConstructor.evaluate_dataset = evaluate_dataset"
      ],
      "metadata": {
        "id": "SwZqXnIilPSC"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This is enough in the model constructor to do some training."
      ],
      "metadata": {
        "id": "bpzGcKpiOCGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "units = 512\n",
        "n_layers = 2\n",
        "isBidirectional = True\n",
        "useAttention = True\n",
        "model = Seq2SeqModelConstructor(\n",
        "    units = units,\n",
        "    input_rxn_processor=rxn_processor,\n",
        "    output_rxn_processor=product_processor, \n",
        "    output_vocab_size=product_processor.vocabulary_size(),\n",
        "    n_layers=n_layers,\n",
        "    layer_type=\"lstm\",\n",
        "    isBidirectional=isBidirectional,\n",
        "    useAttention=useAttention)\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(clipnorm=5),\n",
        "    loss=MaskedLoss()\n",
        ")"
      ],
      "metadata": {
        "id": "8sHHOrR-OB2l"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Note on Training\n",
        "\n",
        "As desceibed at the start I took a subset of my dataset to 1000 reactions for training so that CPU training on the colab wouldn't take too long.\n",
        "\n",
        "BUUUT, that means I can't gaurntee that training will be as good or as effective on this smaller dataset. Because there are potentially alot of reaction patterns, it could be that this 1000 subset is diverse in the kinds of reactions it has, so although epochs will be quick it may have trouble learning. Just something to keep in mind.\n",
        "\n",
        "In testing\n",
        "\n",
        ">units = 512\n",
        "\n",
        ">n_layers = 2\n",
        "\n",
        ">isBidirectional = True\n",
        "\n",
        ">useAttention = True\n",
        "\n",
        "Took about 10 epochs to hit a acc_1 = ~80%\n",
        "\n",
        "So for educational purposes play around and run models, if you want to actually get the accuracy high will likely have to run for awhile!"
      ],
      "metadata": {
        "id": "SDtCbpZ9VZi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h = model.fit(trainDataset, epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykTz7b9iOiMP",
        "outputId": "1df65e85-7c10-4f85-cf12-1c14f1c8f55b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 31s 623ms/step - batch_loss: 2.4676 - acc_1: 0.2546 - acc_2: 0.3754 - acc_3: 0.4771 - acc_4: 0.5674 - acc_5: 0.6474 - totA: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reminder this is Evaluating WITH teacher forcing. Can compare to fit values to see over fitting."
      ],
      "metadata": {
        "id": "zX9K8ph0LCVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h = model.evaluate(testDataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH0KEX0VZ89W",
        "outputId": "7f6b61ae-5e3b-4a8c-a7cd-9c1d965e7dc0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 2s 124ms/step - batch_loss: 2.1555 - acc_1: 0.3879 - acc_2: 0.5406 - acc_3: 0.6421 - acc_4: 0.7297 - acc_5: 0.7890 - totA: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is true evaluation where the decoder is being fed in its last output. These values are the values for actual prediction."
      ],
      "metadata": {
        "id": "q5mtX-1eLJPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h = model.evaluate_dataset(testDataset)\n",
        "print(h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Dp58okamZHf",
        "outputId": "fc480613-ea98-4265-fcbe-e9fc02b6a8ce"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: 0 - batch_loss: 2.227 - acc_1: 0.365 - acc_2: 0.524 - acc_3: 0.635 - acc_4: 0.721 - acc_5: 0.782 - TotA: 0.000\n",
            "Batch: 1 - batch_loss: 2.346 - acc_1: 0.334 - acc_2: 0.464 - acc_3: 0.580 - acc_4: 0.681 - acc_5: 0.745 - TotA: 0.000\n",
            "Batch: 2 - batch_loss: 2.203 - acc_1: 0.355 - acc_2: 0.490 - acc_3: 0.591 - acc_4: 0.678 - acc_5: 0.757 - TotA: 0.000\n",
            "Batch: 3 - batch_loss: 2.375 - acc_1: 0.360 - acc_2: 0.440 - acc_3: 0.550 - acc_4: 0.670 - acc_5: 0.730 - TotA: 0.000\n",
            "{'batch_loss': 2.2877012491226196, 'acc_1': 0.353374719619751, 'acc_2': 0.4794630706310272, 'acc_3': 0.5887938588857651, 'acc_4': 0.687476396560669, 'acc_5': 0.7536693513393402, 'totA': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TODOs for myself, but if you want to play around these are some things to try!\n",
        "\n",
        "!!TODO!!\n",
        "\n",
        "- A prediction function that takes one reaction at a time?\n",
        "- A visualization for attention weights?\n"
      ],
      "metadata": {
        "id": "7fWTFwvdSQMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Yy8jvuP2QZC3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "IWSS_ReactionPrediction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOsYpAu9jFpJYavVP679quN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}